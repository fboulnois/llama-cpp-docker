services:
  llama:
    image: llama-cpp-docker
    environment:
      - LLAMA_ARG_CTX_SIZE=2048
      - LLAMA_ARG_HF_REPO=bartowski/Meta-Llama-3.1-8B-Instruct-GGUF:q5_k_m
      - LLAMA_ARG_N_GPU_LAYERS=99
    volumes:
      - data:/home/llama/.cache
    ports:
      - target: 8080
        published: 8080
        mode: host
volumes:
  data:
